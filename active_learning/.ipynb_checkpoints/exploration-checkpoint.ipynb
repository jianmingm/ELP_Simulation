{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e396d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from botorch import fit_gpytorch_mll\n",
    "from gpytorch.likelihoods import FixedNoiseGaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch import settings\n",
    "\n",
    "from gskgpr import GaussianStringKernelGP\n",
    "from seq2ascii import Seq2Ascii\n",
    "import pickle\n",
    "\n",
    "from botorch.acquisition import PairwiseMCPosteriorVariance\n",
    "from botorch.sampling import SobolQMCNormalSampler\n",
    "from botorch.optim.optimize import optimize_acqf_discrete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c92084-db25-4705-b234-9d8ed256fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(train_x, train_y, err_y, translator,num_outputs):\n",
    "    model = GaussianStringKernelGP(train_x=train_x, train_y=train_y, \n",
    "                            likelihood=FixedNoiseGaussianLikelihood(noise=err_y), \n",
    "                            translator=translator, num_outputs=num_outputs)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model).to(device)\n",
    "    return model, mll\n",
    "\n",
    "def append_star(name):\n",
    "    if len(name) == 45:\n",
    "        return name + '*****'\n",
    "    else:\n",
    "        return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd0e00-6d76-4721-82ca-ca37b3a4216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting names and rounds\n",
    "Previous_Round = 23\n",
    "Current_Round = 24\n",
    "\n",
    "## Names for saving the models and training data\n",
    "training_sample_pickle_file = f'BO_sample_{Current_Round}.pickle'\n",
    "model_name = f'GPR_Model_{Current_Round}.pth'\n",
    "\n",
    "## Read data and ELP library    \n",
    "ELP_all=pd.read_csv('./pickles/FE_all.csv')\n",
    "computed=pd.read_csv('./pickles/FE-latest.csv')\n",
    "\n",
    "dataset = ELP_all.merge(computed[['ELP', 'dG', 'dG_err']], on='ELP', how='left')\n",
    "dataset['Sequence'] = dataset['Sequence'].apply(append_star)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7fedaa-fa02-4332-8283-a5b0e7b602f8",
   "metadata": {},
   "source": [
    "### Fit a GPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3482e6-9e37-45ec-984b-0c355df43973",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get translator\n",
    "translator = Seq2Ascii(\"./AA.blosum62.pckl\")\n",
    "fspace = dataset.Sequence.to_list()\n",
    "translator.fit(fspace)\n",
    "\n",
    "## Get and save training samples\n",
    "dataset_train=dataset.dropna(subset=['dG'], inplace=False)\n",
    "BO_samples = dataset_train[['ELP', 'dG', 'dG_err']].values.tolist()\n",
    "\n",
    "## save the training samples in this round\n",
    "with open(f'./pickles/training_samples/{training_sample_pickle_file}', 'wb') as f:\n",
    "    pickle.dump(BO_samples, f)\n",
    "\n",
    "\n",
    "train_mean=dataset_train['dG'].mean()\n",
    "train_std=dataset_train['dG'].std()\n",
    "\n",
    "## Normalization\n",
    "dataset_train.loc[:, 'dG_err'] = dataset_train['dG_err'] / train_std\n",
    "dataset_train.loc[:, 'dG'] = (dataset_train['dG'] - train_mean) / train_std\n",
    "dataset_train.loc[:, 'dG_var'] = dataset_train['dG_err']**2\n",
    "print('Fitting GPR')\n",
    "\n",
    "## encode, train and save model\n",
    "device='cpu'\n",
    "encoded_x = translator.encode_to_int(dataset_train.loc[:, 'Sequence'].to_list()).to(device)\n",
    "train_y = torch.tensor(dataset_train.dG.to_numpy()).float().to(device)\n",
    "err_y = torch.tensor(dataset_train.dG_var.to_numpy()).float().to(device)\n",
    "\n",
    "model, mll = initialize_model(encoded_x, train_y, err_y, translator, num_outputs=1)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "print(f'Actual sigma1: {model.covar_module.sigma1.item()}')\n",
    "print(f'Actual sigma2: {model.covar_module.sigma2.item()}')\n",
    "torch.save(model.state_dict(), f'./pickles/models/{model_name}')\n",
    "\n",
    "## Prediction\n",
    "full_space = torch.as_tensor(list(translator.int2str.keys())).view(-1, 1).to(device)\n",
    "with torch.no_grad():\n",
    "    post = model.posterior(full_space)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f006c3-8991-49e7-a511-05c653883fd0",
   "metadata": {},
   "source": [
    "### Run an acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2df68c-db93-4ffe-ad89-e61973d476c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Performing qNEI')\n",
    "## qNEI\n",
    "choices = list(translator.int2str.keys())\n",
    "for i in dataset_train.Sequence: # remove the ones that are already in the training set\n",
    "    choices.remove(translator.str2int[i])\n",
    "choices = torch.Tensor(choices).view(-1, 1).to(device)\n",
    "\n",
    "best_value = train_y.max()\n",
    "\n",
    "sampler = SobolQMCNormalSampler(sample_shape=torch.Size([len(choices)]), seed=0)\n",
    "MC_EI = qNoisyExpectedImprovement(model, X_baseline=encoded_x.unsqueeze(1), sampler=sampler)\n",
    "torch.manual_seed(seed=0)  # to keep the restart conditions the same\n",
    "\n",
    "new_point_mc, acqui_value = optimize_acqf_discrete(\n",
    "    acq_function=MC_EI,\n",
    "    q=2,\n",
    "    choices=choices,\n",
    "    max_batch_size=len(choices),\n",
    "    unique=True)\n",
    "\n",
    "decoded_sequences=translator.decode(new_point_mc.squeeze())\n",
    "\n",
    "ELP_name = []\n",
    "for decoded_seq in decoded_sequences:\n",
    "    filtered_row = dataset.loc[dataset['Sequence'] == decoded_seq]\n",
    "    ELP_name.append(filtered_row['ELP'].item())\n",
    "print('Selected Candidates are ')\n",
    "print(ELP_name)\n",
    "\n",
    "with torch.no_grad():\n",
    "    post_candidates = model.posterior(new_point_mc.view(-1, 1))\n",
    "    post_candidates_mean=(post_candidates.mean.detach().numpy()*train_std+train_mean).reshape(-1)\n",
    "    post_candidates_std=(post_candidates.variance.sqrt().detach().numpy()*train_std).reshape(-1)\n",
    "    print(post_candidates_mean, post_candidates_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53988fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
